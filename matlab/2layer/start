Functions for initialization, evaluation and training of a 2-layers neural network with the ReLu as activation for the hidden layer and linear output.

